{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6_sXhwLyO_2"
      },
      "outputs": [],
      "source": [
        "# 1. What is Simple Linear Regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Linear Regression is a statistical method used to model the relationship between two variables:\n",
        "\n",
        "* One independent variable (X) — the predictor or input.\n",
        "\n",
        "* One dependent variable (Y) — the outcome or output.\n",
        "\n",
        "The goal is to find the best-fitting straight line (called the regression line) through the data points that predicts Y based on X."
      ],
      "metadata": {
        "id": "sRE2h4BAyyXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2. What are the key assumptions of Simple Linear Regression?"
      ],
      "metadata": {
        "id": "Co4e5XuYywcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Simple Linear Regression to work properly and give reliable results, several key assumptions must be met. Here they are:\n",
        "* Linearity\n",
        "* Independence of Errors\n",
        "* Homoscedasticity\n",
        "* Normality of Errors\n",
        "* Normality"
      ],
      "metadata": {
        "id": "9gvKO7Hdz0p1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3. What does the coefficient m represent in the equation Y=mX+c?"
      ],
      "metadata": {
        "id": "59x91tjg0UXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the equation:\n",
        "\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "𝑋\n",
        "+\n",
        "𝑐\n",
        "Y=mX+c\n",
        "This is the equation of a straight line, where:\n",
        "\n",
        "* m is the coefficient (also called the slope)\n",
        "It represents:\n",
        "\n",
        "The rate of change in Y for a one-unit increase in X.\n",
        "\n",
        "So if:\n",
        "\n",
        "m = 2, it means every time X increases by 1, Y increases by 2.\n",
        "\n",
        "m = -3, it means every time X increases by 1, Y decreases by 3.\n",
        "\n",
        "In simple linear regression, m tells you how strongly and in what direction X is influencing Y.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "koVA7i5o0YqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4. What does the intercept c represent in the equation Y=mX+c?"
      ],
      "metadata": {
        "id": "av6lr1KY0sI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* c is the intercept\n",
        "It represents the value of Y when X = 0 — where the line crosses the Y-axis."
      ],
      "metadata": {
        "id": "4XnsVGTc0zsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5. How do we calculate the slope m in Simple Linear Regression?"
      ],
      "metadata": {
        "id": "hiJ9KdwA1E_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The slope m in the equation\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "𝑋\n",
        "+\n",
        "𝑐\n",
        "Y=mX+c\n",
        "is calculated using this formula:\n",
        "\n",
        "m=\n",
        "n∑(Xy)\n",
        "∑X∑Y\n",
        "/\n",
        "n∑X\n",
        "2\n",
        " −(∑X)\n",
        "2\n",
        "\n",
        "Where:\n",
        "\n",
        "𝑛\n",
        "n = number of data points\n",
        "\n",
        "∑\n",
        "𝑋\n",
        "𝑌\n",
        "∑XY = sum of the product of corresponding X and Y values\n",
        "\n",
        "∑\n",
        "𝑋\n",
        "∑X,\n",
        "∑\n",
        "𝑌\n",
        "∑Y = sums of X and Y values respectively\n",
        "\n",
        "∑\n",
        "𝑋\n",
        "2\n",
        "∑X\n",
        "2\n",
        "  = sum of squared X values\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kcHJOIzG1MbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#6. What is the purpose of the least squares method in Simple Linear Regression?"
      ],
      "metadata": {
        "id": "z7-UxEEq1_Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The least squares method helps the regression model choose the slope (m) and intercept (c) that make the predictions as accurate as possible — by minimizing the total squared error.\n",
        "\n"
      ],
      "metadata": {
        "id": "UbBPvXGg2EO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#7.  How is the coefficient of determination (R²) interpreted in Simple Linear Regression?"
      ],
      "metadata": {
        "id": "gGNDcSSA2boN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* If the R2 value is 1: \tPerfect fit — the line explains 100% of the variation in Y.\n",
        "\n",
        "* If the R2 value is 0: The model explains none of the variation — predictions are as good as just using the mean of Y.\n",
        "\n",
        "* If the R2 value is 0.75: 75% of the variation in Y is explained by X — pretty good fit.\n",
        "\n",
        "* if the R2 value is <0.5: themodel doesnot explain much."
      ],
      "metadata": {
        "id": "deP4Yb1Q2gPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#8 What is Multiple Linear Regression?"
      ],
      "metadata": {
        "id": "dk1inkq53mZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Linear Regression (MLR) is an extension of Simple Linear Regression, where:\n",
        "\n",
        "Instead of one independent variable (X), you use two or more to predict the dependent variable (Y)."
      ],
      "metadata": {
        "id": "ts2iQx5q35AP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#9. What is the main difference between Simple and Multiple Linear Regression?"
      ],
      "metadata": {
        "id": "9EWbcZj24DUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Linear Regression = 1 independent variable\n",
        "\n",
        "Multiple Linear Regression = 2 or more independent variables"
      ],
      "metadata": {
        "id": "QMegvGRs4I1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#10. What are the key assumptions of Multiple Linear Regression?"
      ],
      "metadata": {
        "id": "U8p_DngK72ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like with Simple Linear Regression, Multiple Linear Regression (MLR) also has some important assumptions that need to be met to make sure your model is valid and reliable.\n",
        "\n",
        "Key Assumptions of Multiple Linear Regression:\n",
        "1. Linearity\n",
        "2. Independence of Errors\n",
        "3. Homoscedasticity\n",
        "4. Normality of Errors\n",
        "5. No Multicollinearity"
      ],
      "metadata": {
        "id": "T2N9Bhf68BRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?"
      ],
      "metadata": {
        "id": "DNZFeUFx9Aqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heteroscedasticity occurs when the variance of the residuals (errors) is not constant across all levels of the independent variable(s).\n",
        "\n",
        "The Heteroscedasticity Affects MLR by\n",
        "* Invalid Inference\n",
        "* Inefficiency\n",
        "* Misleading R²"
      ],
      "metadata": {
        "id": "wcpaNVN89G4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#12. How can you improve a Multiple Linear Regression model with high multicollinearity?"
      ],
      "metadata": {
        "id": "CxuPNycn9vW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multicollinearity is a common issue in Multiple Linear Regression (MLR) when two or more independent variables are highly correlated with each other. This can create problems because the model struggles to determine the individual effect of each variable on the dependent variable.\n",
        "\n",
        "To Improve a MLR Model with High Multicollinearity:\n",
        "* Remove Highly Correlated Variables\n",
        "* Combine Correlated Variables\n",
        "* Regularization Techniques\n",
        "* Centering the Data\n",
        "* Increase Sample Size\n",
        "* Use Partial Least Squares"
      ],
      "metadata": {
        "id": "Er3GuRJt90tY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#13. What are some common techniques for transforming categorical variables for use in regression models?"
      ],
      "metadata": {
        "id": "OD89gG66-ecn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical variables often need to be transformed into a numerical format so they can be used in regression models. There are several common techniques for handling categorical data in regression analysis.\n",
        "\n",
        "1. One-Hot Encoding\n",
        "2. Label Encoding\n",
        "3. Ordinal Encoding\n",
        "4. Target Encoding\n",
        "5. Frequency (Count) Encoding"
      ],
      "metadata": {
        "id": "CQZ6lBmF-k7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#14. What is the role of interaction terms in Multiple Linear Regression?"
      ],
      "metadata": {
        "id": "YFOWuboX_Qrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interaction terms are an essential concept in Multiple Linear Regression (MLR) that can help capture more complex relationships between the independent variables and the dependent variable.\n",
        "\n",
        "The role of Interaction terms are:\n",
        "*Capturing Complex Relationships\n",
        "* Improving Model Accuracy\n",
        "* Making Better Predictions"
      ],
      "metadata": {
        "id": "JAdGgaPi_am0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?"
      ],
      "metadata": {
        "id": "JQg0XMS0BM-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The interpretation of the intercept in Simple Linear Regression (SLR) and Multiple Linear Regression (MLR) is technically similar, but the context and implications can differ significantly.\n",
        "\n",
        "\n",
        "** Simple Linear Regression **\n",
        "* Interpretation of Intercept (\n",
        "𝛽\n",
        "0\n",
        "β\n",
        "0\n",
        "​\n",
        " ):\n",
        "\n",
        "𝛽\n",
        "0\n",
        "β\n",
        "0\n",
        "​\n",
        "  is the predicted value of\n",
        "𝑌\n",
        "Y when\n",
        "𝑋\n",
        "=\n",
        "0\n",
        "X=0.\n",
        "\n",
        "It's the starting point on the y-axis when the independent variable is zero.\n",
        "\n",
        "\n",
        "**Multiple Linear Regression**\n",
        "* Interpretation of Intercept (\n",
        "𝛽\n",
        "0\n",
        "β\n",
        "0\n",
        "​\n",
        " ):\n",
        "\n",
        "𝛽\n",
        "0\n",
        "β\n",
        "0\n",
        "​\n",
        "  is the predicted value of\n",
        "𝑌\n",
        "Y when all independent variables\n",
        "𝑋\n",
        "1\n",
        ",\n",
        "𝑋\n",
        "2\n",
        ",\n",
        ".\n",
        ".\n",
        ".\n",
        ",\n",
        "𝑋\n",
        "𝑛\n",
        "X\n",
        "1\n",
        "​\n",
        " ,X\n",
        "2\n",
        "​\n",
        " ,...,X\n",
        "n\n",
        "​\n",
        "  are zero.\n",
        "\n",
        "This interpretation becomes more abstract and sometimes even meaningless if the combination of all predictors being zero isn't realistic."
      ],
      "metadata": {
        "id": "U457GKHmBSTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#16. What is the significance of the slope in regression analysis, and how does it affect predictions?"
      ],
      "metadata": {
        "id": "QLtEymGGNq6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The slope in regression analysis is one of the most important components—it's what tells you how your predictor variable(s) affect the outcome variable.\n",
        "\n",
        "\n",
        "**It Affects Predictions**\n",
        "\n",
        "* The slope determines the direction and steepness of the prediction line.\n",
        "\n",
        "* A larger absolute value of slope → stronger impact on prediction.\n",
        "\n",
        "* Accurate slope estimates = better predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "tDVhGigNNwJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#17. How does the intercept in a regression model provide context for the relationship between variables?"
      ],
      "metadata": {
        "id": "0vrAYzx7ON4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The intercept in a regression model plays a subtle but important contextual role—even though it's often overlooked. It acts as the baseline or starting value for the outcome variable.\n",
        "\n",
        "\n",
        "The Intercept Provides Context\n",
        "1. Anchors the Regression Line\n",
        "2. Provides a Reference Point\n",
        "3. Contextual Meaning Depends on X=0\n",
        "4. Enables Full Prediction"
      ],
      "metadata": {
        "id": "dGjlRbxLOSX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#18. What are the limitations of using R² as a sole measure of model performance?"
      ],
      "metadata": {
        "id": "a74K2u4wPEPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limitations of Using R² Alone\n",
        "1. Does Not Indicate Causation\n",
        "2. Can Be Misleading in Multiple Regression\n",
        "3. Does Not Reflect Model Accuracy\n",
        "4. Not Useful for Nonlinear Models"
      ],
      "metadata": {
        "id": "d-G_8eujPH1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#19. How would you interpret a large standard error for a regression coefficient?"
      ],
      "metadata": {
        "id": "799d0kbRPlgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A large standard error for a regression coefficient is like a big attached to that coefficient—it means the estimate is not precise, and we can’t trust it much on its own.\n",
        "\n"
      ],
      "metadata": {
        "id": "g1EMHjidPxh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?"
      ],
      "metadata": {
        "id": "VeuvufVdQF4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Identify Heteroscedasticity in Residual Plots\n",
        "\n",
        "* Use a Residuals vs. Fitted Values Plot:\n",
        "\n",
        "Plot the residuals (errors) on the y-axis and the fitted (predicted) values on the x-axis.\n",
        "\n",
        "Important to Address Heteroscedasticity\n",
        "1. Invalid Statistical Inference\n",
        "2. Reduced Model Efficiency\n",
        "3. Can Signal Model Problems"
      ],
      "metadata": {
        "id": "fqBpxj6cQK7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?"
      ],
      "metadata": {
        "id": "JlVj50OpQznY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " If your Multiple Linear Regression (MLR) model has a high R² but low Adjusted R², it’s usually a sign that:\n",
        "\n",
        " **The model includes irrelevant or unnecessary predictors.**\n",
        "\n",
        "* R² (Coefficient of Determination)\n",
        "1. Measures how much of the variance in the dependent variable is explained by all predictors.\n",
        "\n",
        "2. Always increases (or stays the same) when you add more variables—even if they have no real relationship to the outcome.\n",
        "\n",
        "* Adjusted R²\n",
        "1. Adjusts R² based on the number of predictors and sample size.\n",
        "\n",
        "2. Penalizes the model for adding predictors that don’t actually improve the model."
      ],
      "metadata": {
        "id": "0vp4Yga0RIHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Why is it important to scale variables in Multiple Linear Regression?"
      ],
      "metadata": {
        "id": "_CGl6WUVSgtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling variables in Multiple Linear Regression (MLR) isn’t always mandatory, but it’s often very important, especially in certain contexts.\n",
        "\n",
        "Why Scaling Can Be Important in MLR:\n",
        "1. Makes Coefficients Comparable\n",
        "2. Helps with Numerical Stability\n",
        "3. Essential for Regularizatio"
      ],
      "metadata": {
        "id": "fI7yT7xnSkgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#23. What is polynomial regression?"
      ],
      "metadata": {
        "id": "a7NPN9K-TIsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial regression is a type of regression analysis where the relationship between the independent variable(s) and the dependent variable is modeled as an nth-degree polynomial. Instead of fitting a straight line (like in linear regression), a curve is fit to the data."
      ],
      "metadata": {
        "id": "HthHhBy4TNnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#24. How does polynomial regression differ from linear regression?"
      ],
      "metadata": {
        "id": "FiUY1Sv6Tnoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial regression and linear regression are both methods used to model relationships between variables, but they have key differences in how they handle the relationship between the independent and dependent variables.\n",
        "\n",
        "\n",
        " **Linear Regression**\n",
        "\n",
        "In linear regression, the relationship between the independent variable(s)\n",
        "𝑋\n",
        "X and the dependent variable\n",
        "𝑌\n",
        "Y is modeled as a straight line. The model assumes a linear (constant slope) relationship between\n",
        "𝑋\n",
        "X and\n",
        "𝑌\n",
        "Y.\n",
        "\n",
        "Formula:\n",
        "\n",
        "For a single predictor (X):\n",
        "\n",
        "𝑌\n",
        "=\n",
        "𝛽\n",
        "0\n",
        "+\n",
        "𝛽\n",
        "1\n",
        "𝑋\n",
        "+\n",
        "𝜀\n",
        "Y=β\n",
        "0\n",
        "​\n",
        " +β\n",
        "1\n",
        "​\n",
        " X+ε\n",
        "𝑌\n",
        "Y: Dependent variable\n",
        "\n",
        "𝑋\n",
        "X: Independent variable\n",
        "\n",
        "𝛽\n",
        "0\n",
        "β\n",
        "0\n",
        "​\n",
        " : Intercept (where the line crosses the y-axis)\n",
        "\n",
        "𝛽\n",
        "1\n",
        "β\n",
        "1\n",
        "​\n",
        " : Slope (how much\n",
        "𝑌\n",
        "Y changes for a unit change in\n",
        "𝑋\n",
        "X)\n",
        "\n",
        "𝜀\n",
        "ε: Error term\n",
        "\n",
        "\n",
        "**Polynomial Regression**\n",
        "\n",
        "Polynomial regression, on the other hand, extends linear regression by modeling the relationship between the independent variable(s) and the dependent variable as a polynomial (curved line). It allows for non-linear relationships between the variables by adding higher-degree terms (like\n",
        "𝑋\n",
        "2\n",
        ",\n",
        "𝑋\n",
        "3\n",
        ",\n",
        "…\n",
        "X\n",
        "2\n",
        " ,X\n",
        "3\n",
        " ,…) to the equation.\n",
        "\n",
        "Formula:\n",
        "\n",
        "For a single predictor (X) in a polynomial regression of degree\n",
        "𝑛\n",
        "n:\n",
        "\n",
        "𝑌\n",
        "=\n",
        "𝛽\n",
        "0\n",
        "+\n",
        "𝛽\n",
        "1\n",
        "𝑋\n",
        "+\n",
        "𝛽\n",
        "2\n",
        "𝑋\n",
        "2\n",
        "+\n",
        "𝛽\n",
        "3\n",
        "𝑋\n",
        "3\n",
        "+\n",
        "⋯\n",
        "+\n",
        "𝛽\n",
        "𝑛\n",
        "𝑋\n",
        "𝑛\n",
        "+\n",
        "𝜀\n",
        "Y=β\n",
        "0\n",
        "​\n",
        " +β\n",
        "1\n",
        "​\n",
        " X+β\n",
        "2\n",
        "​\n",
        " X\n",
        "2\n",
        " +β\n",
        "3\n",
        "​\n",
        " X\n",
        "3\n",
        " +⋯+β\n",
        "n\n",
        "​\n",
        " X\n",
        "n\n",
        " +ε\n",
        "𝑌\n",
        "Y: Dependent variable\n",
        "\n",
        "𝑋\n",
        "X: Independent variable\n",
        "\n",
        "𝛽\n",
        "0\n",
        ",\n",
        "𝛽\n",
        "1\n",
        ",\n",
        "…\n",
        ",\n",
        "𝛽\n",
        "𝑛\n",
        "β\n",
        "0\n",
        "​\n",
        " ,β\n",
        "1\n",
        "​\n",
        " ,…,β\n",
        "n\n",
        "​\n",
        " : Coefficients to be estimated\n",
        "\n",
        "𝜀\n",
        "ε: Error term"
      ],
      "metadata": {
        "id": "TIiwF7nsTq6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#25. When is polynomial regression used?"
      ],
      "metadata": {
        "id": "85cgXASJUj8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial regression is used when you want to model a non-linear relationship between the independent variable(s) and the dependent variable. While linear regression works well for data that shows a straight-line relationship, polynomial regression comes into play when the data exhibits a curved or more complex pattern."
      ],
      "metadata": {
        "id": "_KSDpYzHUr9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#26. What is the general equation for polynomial regression?"
      ],
      "metadata": {
        "id": "TivtN2WdUxaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The general equation for polynomial regression extends the basic linear regression model to include higher-order terms of the independent variable(s). It allows you to fit a curved relationship between the independent variable(s)\n",
        "𝑋\n",
        "X and the dependent variable\n",
        "𝑌\n",
        "Y."
      ],
      "metadata": {
        "id": "hLlN4C2OU1K4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#27. Can polynomial regression be applied to multiple variables?"
      ],
      "metadata": {
        "id": "VQhwSSrbVS2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, polynomial regression can be applied to multiple variables (predictors). When polynomial regression is extended to multiple variables, it is often referred to as Multiple Polynomial Regression. This allows you to model more complex, non-linear relationships where the dependent variable is influenced by multiple independent variables in a non-linear manner."
      ],
      "metadata": {
        "id": "_r90x4TBVWFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#28. What are the limitations of polynomial regression?"
      ],
      "metadata": {
        "id": "QM0h7TKYWEo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " limitations of polynomial regression:\n",
        "\n",
        "1. Overfitting\n",
        "2. Extrapolation Issues\n",
        "3. Model Complexity\n",
        "4. Multicollinearity\n"
      ],
      "metadata": {
        "id": "wpvNpGbWWI53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#29. What methods can be used to evaluate model fit when selecting the degree of a polynomial"
      ],
      "metadata": {
        "id": "SqEzs_c_WXS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When selecting the degree of a polynomial for polynomial regression, it's crucial to evaluate how well the model fits the data while also ensuring it does not overfit. Overfitting occurs when the model becomes too complex, fitting the noise in the data instead of the underlying relationship, which leads to poor generalization on unseen data. To avoid this, several evaluation methods can be used to help choose the optimal degree of the polynomial."
      ],
      "metadata": {
        "id": "ZFI8jBo_WZs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#30.  Why is visualization important in polynomial regression?"
      ],
      "metadata": {
        "id": "9OlhXtGTW53p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization plays a critical role in polynomial regression for several reasons, as it allows for a more intuitive understanding of how well the model fits the data and helps to diagnose potential issues with the model. Here's why visualization is so important:\n",
        "\n",
        "1. Assessing Model Fit and Complexity\n",
        "2. Detecting Overfitting or Underfitting\n",
        "3. Visualizing the Trade-off Between Bias and Variance\n",
        "4. Identifying Patterns and Trends\n"
      ],
      "metadata": {
        "id": "k04K8lAwW9eG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#31.  How is polynomial regression implemented in Python"
      ],
      "metadata": {
        "id": "v00BZjnQXKOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial regression can be implemented in Python using libraries such as NumPy for handling numerical computations and scikit-learn for building the polynomial regression model."
      ],
      "metadata": {
        "id": "ZC6CMgOhXPQB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CL4AcghEXbhe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}